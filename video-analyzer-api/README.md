# Video Analyzer API

Сервис для автоматического анализа видео и выделения сюжетных линий на основе обнаруженных сцен.

## Возможности

- Автоматическое обнаружение сцен в видео
- Анализ аудио каждой сцены и извлечение транскрипций
- Группировка сцен в сюжетные линии
- Предоставление таймкодов для каждой сцены и сюжетной линии
- Асинхронная обработка видео в фоновом режиме

## Требования

- Docker и Docker Compose

## Установка и запуск

1. Клонируйте репозиторий или создайте структуру проекта

2. Создайте необходимые директории для данных

   ```bash
   mkdir -p shared-data/sample-videos shared-data/results
   ```

3. Добавьте тестовые видеофайлы в директорию `shared-data/sample-videos/`

4. Запустите сервис с помощью Docker Compose

   ```bash
   docker-compose up -d
   ```

5. Проверьте, что сервис запустился
   ```bash
   curl http://localhost:8000/
   ```
   Вы должны увидеть сообщение: `{"status":"ok","message":"Video Analyzer API is running"}`

## API-эндпоинты

### Получение списка доступных видео

```
GET /api/sample-videos
```

**Ответ:**

```json
{
  "videos": ["video1.mp4", "video2.mp4"]
}
```

### Запуск анализа видео

```
POST /api/analyze
```

**Тело запроса:**

```json
{
  "filename": "video1.mp4",
  "num_storylines": 3
}
```

**Ответ:**

```json
{
  "task_id": "video1_3",
  "status": "processing",
  "message": "Анализ видео запущен в фоновом режиме"
}
```

### Проверка статуса анализа

```
GET /api/analysis/{task_id}
```

**Ответ для незавершенной задачи:**

```json
{
  "status": "processing",
  "message": "Обнаружение сцен...",
  "progress": 0.2,
  "last_updated": "2023-07-15T14:30:45.123456"
}
```

**Ответ для завершенной задачи:**

```json
{
  "status": "completed",
  "task_id": "video1_3",
  "result": {
    "video_filename": "video1.mp4",
    "duration": 360.5,
    "total_scenes": 24,
    "storylines": [
      {
        "id": "storyline_1",
        "name": "Сюжетная линия 1",
        "description": "Сюжет длительностью 45.5 секунд, включающий 3 сцены",
        "scenes": [
          {
            "id": "scene_1",
            "start_time": 120.0,
            "end_time": 165.5,
            "duration": 45.5,
            "start_frame": 2880,
            "end_frame": 3972,
            "audio_analysis": {
              "transcript": "Текстовая транскрипция диалога в сцене",
              "language": "ru",
              "audio_features": {
                "rms_energy": 0.12,
                "spectral_centroid_mean": 1560.4,
                "zero_crossing_rate": 0.05,
                "tempo": 95.6
              },
              "speakers": null,
              "emotions": null
            }
          }
        ],
        "duration": 45.5,
        "start_time": 120.0,
        "end_time": 165.5
      }
    ],
    "timestamp": "2023-07-15T14:35:10.123456",
    "metadata": {
      "fps": 24,
      "size": [1920, 1080],
      "analysis_time_seconds": 25.8
    }
  }
}
```

## Принцип работы

1. API принимает запрос на анализ видео из директории `shared-data/sample-videos/`
2. Запускает асинхронный процесс анализа:
   - Извлечение метаданных видео
   - Обнаружение сцен с помощью PySceneDetect
   - Анализ аудио каждой сцены и извлечение транскрипций
   - Группировка сцен в сюжетные линии
3. Результаты сохраняются в формате JSON в директории `shared-data/results/`
4. Клиент может опрашивать статус задачи и получать результаты

## Архитектура пайплайна анализа

Новая архитектура сервиса основана на модульном пайплайне анализа:

1. **Класс AnalysisPipeline**: Главный класс, координирующий процесс анализа

   - Инициализирует и управляет всеми анализаторами
   - Последовательно запускает каждый этап анализа
   - Собирает и объединяет результаты всех этапов

2. **Класс SceneDetector**: Отвечает за обнаружение сцен в видео

   - Использует PySceneDetect для поиска границ сцен
   - Возвращает список сцен с метаданными

3. **Класс AudioAnalyzer**: Анализирует аудио для каждой сцены

   - Извлекает аудиосегмент из видео
   - Транскрибирует речь с помощью Whisper
   - Анализирует аудио-характеристики

4. **Класс StorylineGrouper**: Группирует сцены в сюжетные линии
   - Принимает сцены с результатами аудиоанализа
   - Группирует их на основе временной близости
   - Формирует сюжетные линии с метаданными

Такая модульная архитектура позволяет легко добавлять новые анализаторы (например, для лиц, объектов) без изменения существующего кода.

## Детальное описание алгоритма анализа

Анализ видео состоит из нескольких последовательных этапов:

### 1. Функция `analyze_video`

Основная функция, которая организует весь процесс анализа:

- Получает информацию о видеофайле (длительность, FPS, размеры) с помощью MoviePy
- Вызывает функцию обнаружения сцен
- Группирует сцены в сюжетные линии
- Формирует и сохраняет результаты анализа в JSON-файл
- Обновляет статус задачи на протяжении всего процесса

### 2. Функция `detect_scenes`

Отвечает за определение границ сцен в видео:

- Использует библиотеку PySceneDetect
- Применяет ContentDetector с пороговым значением 27.0 (оптимизировано для большинства видео)
- ContentDetector анализирует изменения в содержимом кадров:
  - Для каждой пары последовательных кадров рассчитывается "значение разницы"
  - Если значение превышает порог, обнаруживается новая сцена
- Возвращает список сцен с информацией о начале, конце и длительности каждой сцены

### 3. Функция `group_scenes_into_storylines`

Объединяет отдельные сцены в логически связанные сюжетные линии:

- Сортирует сцены по длительности (от самых длинных к самым коротким)
- Выбирает N самых длинных сцен как "ключевые" для сюжетных линий (где N - запрошенное количество сюжетов)
- Для каждой ключевой сцены ищет близкие сцены по времени:
  - Рассчитывает "радиус близости" как 10% от общей длительности видео
  - Находит сцены, которые начинаются/заканчиваются в пределах этого радиуса от ключевой сцены
- Объединяет близкие сцены в сюжетную линию и вычисляет её параметры:
  - Общая длительность
  - Время начала и конца
  - Описание

### Параметры и настройки алгоритма

- **Порог обнаружения сцен (threshold)**: 27.0

  - Оптимальное значение для большинства видео
  - Более низкие значения приведут к обнаружению большего количества сцен (более чувствительный анализ)
  - Более высокие значения уменьшат количество обнаруженных сцен (менее чувствительный анализ)

- **Радиус близости сцен**: 10% от общей длительности видео

  - Определяет, насколько близко сцены должны быть по времени, чтобы считаться частью одной сюжетной линии
  - Можно настроить для разных типов контента (для динамичных видео может потребоваться меньшее значение)
  - **Важное ограничение:** Текущий алгоритм основан только на временной близости сцен, что не идеально для сериалов. В реальных сериалах одна сюжетная линия может прерываться другой и возобновляться значительно позже. Например, сцены из сюжетной линии A могут чередоваться со сценами из сюжетной линии B (A → B → A → B), но текущий алгоритм не сможет объединить разделенные во времени сцены A в одну сюжетную линию.

- **Количество сюжетных линий**: определяется пользователем (по умолчанию 3)
  - Задает желаемое количество сюжетных линий для выделения
  - При недостаточном количестве сцен, будет возвращено столько сюжетных линий, сколько возможно

### Будущие улучшения алгоритма

Текущая реализация использует временные и длительностные характеристики сцен, а также анализ аудио. В будущих версиях планируется добавить:

1. ✅ Аудиоанализ и транскрипция речи

   - Транскрипция диалогов с помощью модели Whisper
   - Анализ аудио характеристик для каждой сцены

2. Распознавание персонажей
   Что сделать: Добавить систему распознавания лиц и отслеживания персонажей в видео
   Ожидаемый результат: Список персонажей с временными метками их появления в каждой сцене

3. Семантический анализ сцен
   Что сделать: Разработать алгоритм для анализа содержания сцен и определения их тематической близости
   Ожидаемый результат: Система, группирующая сцены по смыслу, а не только по времени
4. Определение "интересности" сцен
   Что сделать: Создать модель для оценки значимости и интересности каждой сцены
   Ожидаемый результат: Числовая оценка каждой сцены, помогающая выделять ключевые моменты
5. Алгоритм группировки в сюжетные линии
   Что сделать: Разработать алгоритм, объединяющий данные о персонажах, диалогах и семантике для формирования сюжетных линий
   Ожидаемый результат: Автоматическое выделение сюжетных линий, даже если их сцены разделены во времени
6. Система метрик релевантности
   Что сделать: Создать систему оценки принадлежности каждой сцены к сюжетным линиям
   Ожидаемый результат: Показатели релевантности сцен к каждой сюжетной линии
7. Визуализация сюжетных линий
   Что сделать: Разработать интерактивный таймлайн для отображения переплетения сюжетных линий
   Ожидаемый результат: Наглядное представление структуры сюжета с возможностью интерактивного взаимодействия
8. Экспорт сюжетных линий
   Что сделать: Добавить возможность экспорта отдельных сюжетных линий как видеофрагментов
   Ожидаемый результат: Функционал для получения готовых видеонарезок по каждой сюжетной линии
9. Система обратной связи для улучшения
   Что сделать: Внедрить механизм сбора пользовательских корректировок для улучшения моделей
   Ожидаемый результат: Постоянное повышение точности автоматического анализа
10. Адаптация для разных типов контента
    Что сделать: Расширить поддержку для различных жанров и форматов видео
    Ожидаемый результат: Универсальная система, работающая с любым видеоконтентом

Доп комменты:

1. Для анализа сюжетных линий можно строить граф связей между сценами
   💬 Комментарий: можно создать граф сюжетной связи, где:
   узлы — это сцены,
   рёбра — это:
   общие объекты,
   общие персонажи,
   причинно-следственная связь (если найдена через GPT).

2. Сохраняй все объекты и события для поиска по будущим сценам
   💬 Комментарий: при анализе сцены сохраняй список:
   ```
     {
     objects: ['flash drive', 'door', 'safe'],
     people: ['unknown man'],
     actions: ['enter', 'steal', 'run'],
     sceneId: 's12'
     }
   ```
   — Когда ты дойдёшь до сцены 40 и найдёшь «герой говорит: флешка пропала» — ты сможешь найти по ключевому слову “flash drive” прошлые сцены, где это упоминалось / присутствовало.

## Дополнительные настройки

Можно изменить порт и другие настройки в файле `docker-compose.yml`:

```yaml
services:
  video-analyzer:
    ...
    ports:
      - "8000:8000"  # Изменить первое число для другого внешнего порта
    ...
```
